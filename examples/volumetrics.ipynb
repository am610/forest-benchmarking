{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetrics\n",
    "\n",
    "\n",
    "This module that generates circuits on a graph which represents the QPU or QVM lattice. The basic idea is it will compute error rates of circuits as a function of depth and width.\n",
    "\n",
    "The `width` of the circuit is the number of connected vertices on a particular subgraph.\n",
    "\n",
    "The `depth` is defined in an unusual way. We consider a \"depth 1\" circuit to be a round of X gates randomly applied or not to a particular vertex AND a round of CNOTs randomly applied or not to each edge of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# from scipy.spatial.distance import hamming\n",
    "# import scipy.interpolate\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pyquil.api import get_qc, QuantumComputer, get_benchmarker\n",
    "from pyquil.gates import CNOT, CCNOT, Z, X, I, H, CZ, MEASURE, RESET\n",
    "from pyquil.quilbase import Pragma\n",
    "\n",
    "from forest.benchmarking.volumetrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to run on a \"real lattice\"\n",
    "from pyquil import *\n",
    "#list_quantum_computers()\n",
    "#qc_perfect = get_qc(\"Aspen-1-16Q-A\", as_qvm=True, noisy=False)\n",
    "#qc_noisy = get_qc(\"Aspen-1-16Q-A\") #, as_qvm=True, noisy=True)\n",
    "\n",
    "noisy_qc = get_qc(\"9q-square-qvm\", as_qvm=True, noisy=False)\n",
    "perfect_qc = get_qc(\"9q-square-qvm\", as_qvm=True, noisy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(perfect_qc.qubit_topology(),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = perfect_qc.qubit_topology()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gate sets\n",
    "\n",
    "### Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_q_id(qb1,qb2):\n",
    "    prog = Program()\n",
    "    prog +=I(qb1)\n",
    "    prog +=I(qb2)\n",
    "    return prog\n",
    "\n",
    "one_c_gates = [X,I]\n",
    "two_c_gates = [two_q_id,CNOT]\n",
    "two_c_toffoli = [two_q_id, CNOT, CCNOT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_q_gates = [X,Z,I]\n",
    "two_q_gates = [two_q_id,CZ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cliffords\n",
    "\n",
    "We use a benchmarker for this. Typically we use the native gates from `get_rb_gateset` to implement each clifford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest.benchmarking.randomized_benchmarking import get_rb_gateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my config has gone all cattywampus so i need to do this\n",
    "bm = get_benchmarker()#endpoint='tcp://localhost:6000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.client.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get random gates on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog1 = random_single_qubit_gates(G, one_q_gates)\n",
    "prog2 = random_two_qubit_gates(G, two_q_gates)\n",
    "print(prog1+prog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progy = random_single_qubit_cliffords(bm, G)\n",
    "print(progy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some circuit templates and sample programs from them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_1q_layer = get_rand_1q_template(one_c_gates)\n",
    "print(classical_1q_layer.sample_program(G, repetitions=2, width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_2q_layer = get_rand_2q_template(two_c_gates)\n",
    "print(classical_2q_layer.sample_program(G, repetitions=2, width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clifford_1q_layer = get_rand_1q_cliff_template(bm)\n",
    "clifford_2q_layer = get_rand_2q_cliff_template(bm)\n",
    "print(clifford_2q_layer.sample_program(G, repetitions=2, width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_perm_layer = get_rand_qubit_perm_template()\n",
    "print(rand_perm_layer.sample_program(G, 1, qc=noisy_qc, width=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_su4_layer = get_rand_su4_template()\n",
    "print(rand_su4_layer.sample_program(G, 1, qc=noisy_qc, width=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_1q_2q = classical_1q_layer + classical_2q_layer\n",
    "print(classical_1q_2q.sample_program(G, repetitions=2, width=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Volume (unoptimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qv_template = rand_perm_layer + rand_su4_layer\n",
    "print(qv_template.sample_program(G, repetitions=2, qc=noisy_qc, width=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "circuit_depth = 3\n",
    "circuit_width = 3\n",
    "circuit_sandwich = partial(circuit_sandwich_rand_gates,\n",
    "                           one_q_gates = one_c_gates, \n",
    "                           two_q_gates = two_c_gates)\n",
    "layer_dagger = False\n",
    "sandwich_dagger = False\n",
    "num_rand_subgraphs = 2\n",
    "num_shots_per_circuit = 2\n",
    "use_active_reset= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = generate_sandwich_circuits_experiments(qc_noisy,circuit_depth,circuit_width, circuit_sandwich, layer_dagger, sandwich_dagger, num_rand_subgraphs, num_shots_per_circuit, use_active_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = acquire_circuit_sandwich_data(qc_noisy,exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_random_classical_circuit_errors(qc_perfect,daty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the distribution of sublattice widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = qc_perfect.qubit_topology()\n",
    "len(qc_perfect.qubit_topology())\n",
    "# distribution of graph lengths\n",
    "disty = []\n",
    "for gdx in range(1,len(G.nodes)+1):\n",
    "    listg = generate_connected_subgraphs(G,gdx)\n",
    "    disty.append(len(listg))\n",
    "\n",
    "cir_wid = list(range(1,len(G.nodes)+1))\n",
    "plt.bar(cir_wid, disty, width=0.61, align='center')\n",
    "plt.xticks(cir_wid)\n",
    "plt.xlabel('sublattice / circuit width')\n",
    "plt.ylabel('Frequency of Occurence')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.title('Distribution of sublattice widths')\n",
    "disty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire data in Z basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with these parameters the cell below takes about 1 hour 40 minutes\n",
    "# num_shots_per_circuit = 400\n",
    "# num_rand_subgraphs = 16\n",
    "# circuit_depth = 18\n",
    "# circuit_width = 15 #max = len(G.nodes)\n",
    "# x_basis = False\n",
    "# active_reset = True\n",
    "# total == 6077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with these parameters the cell below takes about 5 minutes\n",
    "num_shots_per_circuit = 1000\n",
    "num_rand_subgraphs = 20\n",
    "circuit_depth = 6\n",
    "circuit_width = 4 #max = len(G.nodes)\n",
    "x_basis = False\n",
    "active_reset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp =generate_rand_cir_for_rand_lattices_experiments(qc_noisy, \n",
    "                                                     circuit_depth, \n",
    "                                                     circuit_width,\n",
    "                                                     num_rand_subgraphs, \n",
    "                                                     num_shots_per_circuit, \n",
    "                                                     in_x_basis=x_basis, \n",
    "                                                     use_active_reset=active_reset)\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "data_zbasis = acquire_data_random_classical_circuit(qc_perfect, qc_noisy, exp)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zbasis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_zbasis.to_pickle(\"data_z_Aspen-1-16Q-A_2019_02_16.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zbasis = pd.read_pickle('data_z_Aspen-1-16Q-A_2019_02_16.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit_width = df['Width'].max()\n",
    "# circuit_depth = df['Depth'].max()\n",
    "# for depth, subgraph_size in itertools.product(range(1, circuit_depth+1), range(1, circuit_width+1)):\n",
    "#     print(depth,subgraph_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz = pd.DataFrame(data_zbasis)\n",
    "dfz.to_pickle(\"data_z_Aspen_1_15Q_A_2019_02_09.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data_z_Aspen_1_15Q_A_2019_02_09.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire data in X basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_xbasis = exp.copy()\n",
    "exp_xbasis['In X basis']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0x = time.time()\n",
    "data_xbasis = acquire_data_random_classical_circuit(qc_perfect, qc_noisy, exp_xbasis)\n",
    "t1x = time.time()\n",
    "totalx = t1x-t0x\n",
    "print(totalx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame(data_xbasis)\n",
    "dfx.to_pickle(\"data_x_Aspen_1_15Q_A_2019_02_09.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now put the data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_xbasis.to_pickle(\"data_x_Aspen-1-16Q-A_2019_02_16.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_xbasis = pd.read_pickle('data_x_Aspen-1-16Q-A_2019_02_16.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing and estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = estimate_random_classical_circuit_errors(data_zbasis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_width = res_df['Width'].max()\n",
    "\n",
    "for subgraph_size in range(1, circuit_width+1):\n",
    "    wdx = data_zbasis['Width']==subgraph_size\n",
    "    res_df[wdx]\n",
    "    \n",
    "    df.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_width = res_df['Width'].max()\n",
    "circuit_depth = res_df['Depth'].max()\n",
    "results = []\n",
    "for depth, subgraph_size in itertools.product(range(1, circuit_depth+1), range(1, circuit_width+1)):\n",
    "    wdx = data_zbasis['Width']==subgraph_size\n",
    "    ddx = data_zbasis['Depth']==depth\n",
    "    ndf= res_df[wdx&ddx].copy()\n",
    "    results.append({'Depth': depth,\n",
    "                    'Width': subgraph_size,\n",
    "                    'In X basis': ndf['In X basis'].iloc[0],\n",
    "                    'Active Reset': ndf['Active Reset'].iloc[0],\n",
    "                    'Trials': ndf['Trials'].iloc[0],\n",
    "                    'Hamming dist. data': ndf['Hamming dist. data'].mean(),\n",
    "                    'Hamming dist. rand': ndf['Hamming dist. rand'].mean(),\n",
    "                    'Hamming dist. ideal': ndf['Hamming dist. ideal'].mean(),\n",
    "                    'TVD(data, ideal)': ndf['TVD(data, ideal)'].mean(),\n",
    "                    'TVD(data, rand)': ndf['TVD(data, rand)'].mean(),\n",
    "                    'Pr. success data': ndf['Pr. success data'].mean(),\n",
    "                    'Pr. success rand': ndf['Pr. success rand'].mean(),\n",
    "                    'loge = basement[log_2(Width)-1]': ndf['loge = basement[log_2(Width)-1]'].mean(),\n",
    "                    'Pr. success loge data': ndf['Pr. success loge data'].mean(),\n",
    "                    'Pr. success loge rand': ndf['Pr. success loge rand'].mean(),\n",
    "                    })    \n",
    "munged = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "munged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df[wdx&ddx]['Hamming dist. data'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df[wdx&ddx]['Hamming dist. rand'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a particular depth and width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = 6\n",
    "wid = 4\n",
    "\n",
    "distz = get_hamming_dist(res_df, dep, wid)\n",
    "\n",
    "\n",
    "# combine data from different subgraphs\n",
    "avg_dist = distz['Hamming dist. data'].mean()\n",
    "\n",
    "# rand data\n",
    "rand_dist = distz['Hamming dist. rand'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = np.arange(0, len(avg_dist))\n",
    "plt.bar(x_labels, avg_dist, width=0.61, align='center')\n",
    "plt.bar(x_labels, rand_dist, width=0.31, align='center')\n",
    "plt.xticks(x_labels)\n",
    "plt.xlabel('Hamming Weight of Error')\n",
    "plt.ylabel('Relative Frequency of Occurence')\n",
    "plt.ylim([0,1])\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.legend(['data','random'])\n",
    "plt.title('Depth = {}, Width = {}'.format(dep,wid))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For a particular width plot all depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wid = 4\n",
    "df_fn_depth = get_hamming_dists_fn_depth(res_df, wid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dep in range(1, df_fn_depth.Depth.max()+1):\n",
    "    idx = df_fn_depth['Depth']== dep\n",
    "    avg_dist = df_fn_depth[idx]['Hamming dist. data'].mean() \n",
    "    rand_dist = df_fn_depth[idx]['Hamming dist. rand'].mean() \n",
    "    x_labels = np.arange(0, len(avg_dist))\n",
    "    plt.subplot(1,df_fn_depth.Depth.max(),dep)\n",
    "    plt.bar(x_labels, avg_dist, width=0.61, align='center')\n",
    "    plt.bar(x_labels, rand_dist, width=0.31, align='center')\n",
    "    plt.xticks(x_labels)\n",
    "    plt.xlabel('Hamming Weight of Error')\n",
    "    plt.ylabel('Relative Frequency of Occurence')\n",
    "    plt.ylim([0,1])\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.legend(['data','random'])\n",
    "    plt.title('Depth = {}, Width = {}'.format(dep,wid))\n",
    "plt.subplots_adjust(bottom=0.1, right=3.2, top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can study the sucess probablity, i.e. the zero hamming weight entry above as a function of depth. We first need to extract the data fron the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_vec = []\n",
    "pcheck = []\n",
    "pcheck_rand = []\n",
    "pcheck_log_errors = []\n",
    "pcheck_log_errors_rand = []\n",
    "tvd_rand = []\n",
    "tvd_ideal = []\n",
    "\n",
    "for dep in range(1, df_fn_depth.Depth.max()+1):\n",
    "    idx = df_fn_depth['Depth']== dep\n",
    "    depth_vec.append(dep)\n",
    "    pcheck.append(df_fn_depth[idx]['Pr. success data'].mean()) \n",
    "    pcheck_rand.append(df_fn_depth[idx]['Pr. success rand'].mean())\n",
    "    pcheck_log_errors.append(df_fn_depth[idx]['Pr. success loge data'].mean())\n",
    "    pcheck_log_errors_rand.append(df_fn_depth[idx]['Pr. success loge rand'].mean())\n",
    "    tvd_ideal.append(df_fn_depth[idx]['TVD(data, ideal)'].mean())\n",
    "    tvd_rand.append(df_fn_depth[idx]['TVD(data, rand)'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success probablity and success probablity including a small number of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will plot the success probablity of a circuit with a certain width as a function of depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(depth_vec,pcheck,label='Sucess Probablity')\n",
    "plt.plot(depth_vec,pcheck_rand,label='random guess')\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Pr(success)')\n",
    "plt.title('Pr(success) vs Depth for Width = {}'.format(wid))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sucess if we allow for a small number of errors**\n",
    "\n",
    "Some near term algorithms have robustness to noise. In light of that we might want to consider answers that are only a little wrong successes.\n",
    "\n",
    "To make this notion formal we allow a logarithmic number of bits to flip from the correct answer and call all such instances \"success\".\n",
    "\n",
    "The logarithmic number of bits that we allow to flip is defined by the \"basement\" ${\\mathcal B}$ of \n",
    "\n",
    "$\\log_2 ({\\rm number\\ of\\ bits}) -1$\n",
    "\n",
    "where the basement of a number is ${\\mathcal B}(number) = 0$ if number$<=0$ and ${\\mathcal B}(number) = {\\rm floor (number)}$.\n",
    "\n",
    "\n",
    "Supose we have a circuit of width 4, this means correct string has four bits, e.g. 1010. Then a logarithmic number of flips is $\\log_2(4)-1 = 1$.\n",
    "\n",
    "So any string with hamming weight zero or one counts as a success.\n",
    "\n",
    "Such error metrics might be important in noisy near term algorithms where getting the exact answer is not vital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(depth_vec,pcheck,label='Sucess Probablity')\n",
    "plt.plot(depth_vec,pcheck_rand,label='random guess')\n",
    "plt.scatter(depth_vec,pcheck_log_errors,label='Sucess Probablity + log errors')\n",
    "plt.plot(depth_vec,pcheck_log_errors_rand,label='random guess + log errors')\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Pr(success+log errors)')\n",
    "plt.title('Pr(success+log errors) vs Depth for Width = {}'.format(wid))\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total variation distance from ideal answer and random distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(depth_vec,tvd_ideal,label='TVD(data, ideal)')\n",
    "plt.scatter(depth_vec,tvd_rand,label='TVD(data, rand)')\n",
    "plt.scatter(depth_vec,1-np.asarray(pcheck),label='1-Sucess Probablity',alpha=0.33,marker='^',s=80)\n",
    "#plt.plot(depth_vec,pcheck_log_errors_rand,label='random guess + log errors')\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Total variation distance')\n",
    "plt.title('Width = {}'.format(wid))\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot depth = width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = min([max(res_df['Depth']),max(res_df['Width'])])\n",
    "\n",
    "for idx in range(1,max_idx+1):\n",
    "    distz = get_hamming_dist(res_df, idx, idx)\n",
    "    # combine data from different subgraphs\n",
    "    avg_dist = distz['Hamming dist. data'].mean()\n",
    "    # rand data\n",
    "    rand_dist = distz['Hamming dist. rand'][0]\n",
    "    dep = idx\n",
    "    wid = idx\n",
    "    x_labels = np.arange(0, len(avg_dist))\n",
    "    plt.subplot(1,max_idx,idx)\n",
    "    plt.bar(x_labels, avg_dist, width=0.61, align='center')\n",
    "    plt.bar(x_labels, rand_dist, width=0.31, align='center')\n",
    "    plt.xticks(x_labels)\n",
    "    plt.xlabel('Hamming Weight of Error')\n",
    "    plt.ylabel('Relative Frequency of Occurence')\n",
    "    plt.ylim([0,1])\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.legend(['data','random'])\n",
    "    plt.title('Depth = {}, Width = {}'.format(dep,wid))\n",
    "plt.subplots_adjust(bottom=0.1, right=3.2, top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot success probablity landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just the success probablity as a function of depth and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.asarray([munged['Pr. success data'][idx] for idx in munged.index])\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_rand = np.asarray([munged['Pr. success rand'][idx] for idx in munged.index])\n",
    "values_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(min(res_df['Depth']), max(res_df['Depth'])+1)\n",
    "\n",
    "y = np.arange(min(res_df['Width']), max(res_df['Width'])+1)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1,x2) = X.shape\n",
    "Zdata = np.reshape(values,(x2,x1)).T\n",
    "Zrand = np.reshape(values_rand,(x2,x1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = min(res_df['Depth'])-0.5, max(res_df['Depth'])+0.5, min(res_df['Width'])-0.5, max(res_df['Width'])+0.5\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(Zdata, interpolation='none', extent=extent,\n",
    "                cmap='viridis', origin='lowerleft', vmin=0.0,vmax=1.0)\n",
    "\n",
    "xticks = np.arange(1,max(res_df['Depth'])+1)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(map(str, xticks))\n",
    "\n",
    "yticks = np.arange(1,max(res_df['Width'])+1)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(map(str, yticks))\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Width')\n",
    "plt.title('Success Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = min(res_df['Depth'])-0.5, max(res_df['Depth'])+0.5, min(res_df['Width'])-0.5, max(res_df['Width'])+0.5\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(Zrand, interpolation='none', extent=extent,\n",
    "                cmap='viridis', origin='lowerleft', vmin=0.0,vmax=1.0)\n",
    "\n",
    "xticks = np.arange(1,max(res_df['Depth'])+1)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(map(str, xticks))\n",
    "\n",
    "yticks = np.arange(1,max(res_df['Width'])+1)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(map(str, yticks))\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Width')\n",
    "plt.title('Success Probability of Random Guess')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvd_rand_values = np.asarray([munged['TVD(data, rand)'][idx] for idx in munged.index])\n",
    "tvd_ideal_values = np.asarray([munged['TVD(data, ideal)'][idx] for idx in munged.index])\n",
    "Ztvd_rand = np.reshape(tvd_rand_values,(x2,x1)).T\n",
    "Ztvd_ideal = np.reshape(tvd_ideal_values,(x2,x1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvd_ideal_values\n",
    "tvd_rand_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = min(res_df['Depth'])-0.5, max(res_df['Depth'])+0.5, min(res_df['Width'])-0.5, max(res_df['Width'])+0.5\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(Ztvd_ideal, interpolation='none', extent=extent,\n",
    "                cmap='viridis', origin='lowerleft', vmin=0.0,vmax=1.0)\n",
    "\n",
    "xticks = np.arange(1,max(res_df['Depth'])+1)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(map(str, xticks))\n",
    "\n",
    "yticks = np.arange(1,max(res_df['Width'])+1)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(map(str, yticks))\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Width')\n",
    "plt.title('Success Probability of Random Guess')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = min(res_df['Depth'])-0.5, max(res_df['Depth'])+0.5, min(res_df['Width'])-0.5, max(res_df['Width'])+0.5\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(Ztvd_rand, interpolation='none', extent=extent,\n",
    "                cmap='viridis', origin='lowerleft', vmin=0.0,vmax=1.0)\n",
    "\n",
    "xticks = np.arange(1,max(res_df['Depth'])+1)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(map(str, xticks))\n",
    "\n",
    "yticks = np.arange(1,max(res_df['Width'])+1)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(map(str, yticks))\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Width')\n",
    "plt.title('Success Probability of Random Guess')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loge_rand_values = np.asarray([munged['Pr. success loge rand'][idx] for idx in munged.index])\n",
    "loge_data_values = np.asarray([munged['Pr. success loge data'][idx] for idx in munged.index])\n",
    "Zlge_rand = np.reshape(loge_rand_values,(x2,x1)).T\n",
    "Zlge_data = np.reshape(loge_data_values,(x2,x1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = min(res_df['Depth'])-0.5, max(res_df['Depth'])+0.5, min(res_df['Width'])-0.5, max(res_df['Width'])+0.5\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(Zlge_data, interpolation='none', extent=extent,\n",
    "                cmap='viridis', origin='lowerleft', vmin=0.0,vmax=1.0)\n",
    "\n",
    "xticks = np.arange(1,max(res_df['Depth'])+1)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(map(str, xticks))\n",
    "\n",
    "yticks = np.arange(1,max(res_df['Width'])+1)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(map(str, yticks))\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Width')\n",
    "plt.title('Success Probability of Random Guess')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = min(res_df['Depth'])-0.5, max(res_df['Depth'])+0.5, min(res_df['Width'])-0.5, max(res_df['Width'])+0.5\n",
    "ax = plt.gca()\n",
    "img = ax.imshow(Zlge_rand, interpolation='none', extent=extent,\n",
    "                cmap='viridis', origin='lowerleft', vmin=0.0,vmax=1.0)\n",
    "\n",
    "xticks = np.arange(1,max(res_df['Depth'])+1)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(map(str, xticks))\n",
    "\n",
    "yticks = np.arange(1,max(res_df['Width'])+1)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(map(str, yticks))\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Width')\n",
    "plt.title('Success Probability of Random Guess')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = Y.shape\n",
    "width_1d = Y.reshape((1,np.prod(size)))\n",
    "depth_1d = X.reshape((1,np.prod(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d = Zdata.reshape((1,np.prod(size)))\n",
    "data_1d.shape\n",
    "width_1d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = np.zeros_like(width_1d)\n",
    "dims[0,0] = size[0]\n",
    "dims[0,1] = size[1]\n",
    "\n",
    "xdata = np.vstack((dims,width_1d, depth_1d))\n",
    "\n",
    "\n",
    "\n",
    "xdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two parameter model \n",
    "\n",
    "\n",
    "$f(W,D,p_W,p_D) =  (1-p_W)^W * (1-p_D)^D $\n",
    "\n",
    "The fidelity is proporional to $1 - p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_param(x,pw,pd):\n",
    "    temp = x[0]\n",
    "    wid = temp[0]\n",
    "    dep = temp[1]\n",
    "    width = x[1].reshape(wid,dep)\n",
    "    depth = x[2].reshape(wid,dep)\n",
    "    pcheck = (1-pw)**(width) * (1-pd)**depth\n",
    "    rpcheck = pcheck.reshape((1,wid*dep))\n",
    "    return rpcheck.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One parameter model\n",
    "\n",
    "$f(W,D,p) =  (1-p)^{W * D} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_param(x,p):\n",
    "    temp = x[0]\n",
    "    wid = temp[0]\n",
    "    dep = temp[1]\n",
    "    width = x[1].reshape(wid,dep)\n",
    "    depth = x[2].reshape(wid,dep)\n",
    "    pcheck = (1-p)**(width*depth)\n",
    "    rpcheck = pcheck.reshape((1,wid*dep))\n",
    "    return rpcheck.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my prior work a better model to fit to is\n",
    "\n",
    "Pcheck$(W,D,p,a,b,c) = \\exp[ -(a p^2 + b p + c)* W*D] $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_param_exp(x,p,a,b):\n",
    "    temp = x[0]\n",
    "    wid = temp[0]\n",
    "    dep = temp[1]\n",
    "    width = x[1].reshape(wid,dep)\n",
    "    depth = x[2].reshape(wid,dep)\n",
    "    pcheck = np.exp(-(a*p + b) * width * depth)\n",
    "    rpcheck = pcheck.reshape((1,wid*dep))\n",
    "    return rpcheck.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start with one paramter model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pguess = 0.1\n",
    "popt, pcov = curve_fit(one_param, xdata, data_1d.ravel(), p0=pguess, bounds=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The estimated error is p = ', str(np.round(popt[0],4)))\n",
    "print('The estimated product of the one and two qubit fidelity is F = ', str(1-np.round(popt[0],4)))\n",
    "#print('The one standard deviation on the estimate is ', str(np.round(np.sqrt(np.diag(pcov)[0]),5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfit = one_param(xdata,popt)\n",
    "Z_fit = zfit.reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(X,Y, Z_fit)\n",
    "plt.xticks(list(range(1,circuit_depth+1)))\n",
    "plt.yticks(list(range(1,circuit_width+1)))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(X,Y,Zdata)\n",
    "plt.xticks(list(range(1,circuit_depth+1)))\n",
    "plt.yticks(list(range(1,circuit_width+1)))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two parameter model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pguess2d = [0.0276, 0.01, 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt2d, pcov2d = curve_fit(two_param_exp, xdata, data_1d.ravel(), p0=pguess2d , bounds=(0., 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfit2d = two_param(xdata,popt2d[0],popt2d[1])\n",
    "Z_fit2d = zfit2d.reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(X,Y, Z_fit2d)\n",
    "plt.xticks(list(range(1,circuit_depth+1)))\n",
    "plt.yticks(list(range(1,circuit_width+1)))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-1.02319786e-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
